**DSA in Java â€“ Time and Space Complexity (Interview Guide)**

---

### ğŸ” Definition (in Simple English)

**Time Complexity (TC)** tells us how the *execution time* of an algorithm increases as the input size increases.

**Space Complexity (SC)** tells us how much *extra memory* an algorithm needs as the input grows.

These are used to analyze and compare how efficient algorithms are, especially for large datasets.

---

### ğŸ›ï¸ Real-Life Analogies

* **Time Complexity**: Like estimating how long it takes you to complete homework depending on the number of questions. More questions = more time.

* **Space Complexity**: Like needing more paper to solve more math problems. Larger inputs = more memory.

---

### âš–ï¸ Order of Complexity Analysis

In increasing order of time cost:

* **O(1)** â€“ Constant time (fastest)
* **O(log n)** â€“ Binary search, divide and conquer steps
* **O(n)** â€“ Linear time, scanning
* **O(n log n)** â€“ Efficient sorting (merge sort, quick sort avg case)
* **O(n^2)** â€“ Nested loops (bubble sort, selection sort)
* **O(2^n), O(n!)** â€“ Exponential (recursive subsets, permutations)

---

### âŒ› Time Complexity in Detail

#### **Merge Sort vs Quick Sort**

* **Merge Sort**:

  * TC = O(n log n) â€“ Always
  * SC = O(n) â€“ Needs extra array

* **Quick Sort**:

  * Best/Average: O(n log n)
  * Worst Case: O(n^2)
  * SC = O(log n) â€“ Due to recursion stack

---

### ğŸ“Š Big O, Omega, Theta

| Notation          | Meaning      | Usage                   |
| ----------------- | ------------ | ----------------------- |
| **O (Big O)**     | Worst case   | Most common, safe bound |
| **Î© (Big Omega)** | Best case    | Shows best performance  |
| **Î˜ (Theta)**     | Average case | When best = worst       |

---

### ğŸ”¹ Common Complexities (Graph Overview)

```
O(1) < O(log n) < O(n) < O(n log n) < O(n^2) < O(2^n) < O(n!)
```

Use this to judge how efficient your algorithm is.

---

### ğŸ“‚ Space Complexity

**Space = Input Space + Auxiliary Space**

* **Input Space**: Memory for input
* **Auxiliary Space**: Extra memory used (stack, arrays, etc.)

> Example: Merge sort uses O(n) extra space (new arrays).

---

### âŸ³ Loops and Complexity

* **Simple Loop**: `for (int i = 0; i < n; i++)` â†’ O(n)

* **Nested Loop**:

  ```java
  for (int i = 0; i < n; i++) {
     for (int j = 0; j < n; j++) {
         // work
     }
  }
  ```

  â†’ O(n^2)

* Loop inside while, variable update â†’ Depends on update rate

---

### â†• Sorting Complexities

| Algorithm   | Time Complexity             | Space Complexity |
| ----------- | --------------------------- | ---------------- |
| Bubble Sort | O(n^2)                      | O(1)             |
| Merge Sort  | O(n log n)                  | O(n)             |
| Quick Sort  | O(n log n) avg/worst O(n^2) | O(log n)         |

---

### âŒ– Binary Search

* Efficient for **sorted arrays**
* Time Complexity: **O(log n)**
* Space: O(1) iterative / O(log n) recursive

```java
int binarySearch(int[] arr, int key) {
    int low = 0, high = arr.length - 1;
    while (low <= high) {
        int mid = (low + high) / 2;
        if (arr[mid] == key) return mid;
        else if (arr[mid] < key) low = mid + 1;
        else high = mid - 1;
    }
    return -1;
}
```

---

### ğŸ”„ Recursive Algorithms

#### Linear Recursion

* Ex: Factorial, Fibonacci
* TC = O(n), SC = O(n) (stack calls)

#### Divide & Conquer

* Ex: Merge sort
* TC = O(n log n), SC = O(n)

#### Power Function Variants

1. `power(n)` â†’ TC = O(n), SC = O(n)
2. Optimized divide: TC = O(log n), SC = O(log n)

```java
int power(int x, int n) {
    if (n == 0) return 1;
    int half = power(x, n / 2);
    if (n % 2 == 0) return half * half;
    else return x * half * half;
}
```

---

### ğŸ” How to Approach DSA Questions

1. **Understand the Problem Statement Clearly**
2. **Identify Input/Output formats**
3. **Check for edge cases (null, empty, large size)**
4. **Choose the right data structure (array, stack, tree, etc.)**
5. **Think of the Brute-force solution first**
6. **Then optimize it using logic, sorting, hashing, etc.**
7. **Analyze Time and Space Complexity**
8. **Dry run on paper before coding**
9. **Write clean and readable code**
10. **Test on multiple cases**

---

### ğŸ¤” Common Mistakes to Avoid

* Ignoring worst-case scenarios
* Forgetting recursive space (stack)
* Misunderstanding nested loops complexity
* Optimizing prematurely
* Not considering input constraints

---

### ğŸš€ Interview Tips

* Always mention **TC and SC** after solving
* For every code, explain logic + dry run
* Use proper terms: *linear*, *logarithmic*, *quadratic*, etc.
* Clarify brute-force before optimal
* If confused, discuss trade-offs

---

### ğŸ“… Tips to Master Time and Space Complexity

* Solve pattern-based problems (like nested loops, recursion, divide & conquer)
* Track time/space while solving LeetCode/DSA
* Watch videos and dry run examples
* Make a flashcard with common Big-O notations
* Learn to write recurrence relations for recursive functions

---

### ğŸ“„ Summary Table

| Algorithm / Concept          | Time Complexity     | Space Complexity |
| ---------------------------- | ------------------- | ---------------- |
| Bubble Sort                  | O(n^2)              | O(1)             |
| Merge Sort                   | O(n log n)          | O(n)             |
| Quick Sort                   | O(n log n) / O(n^2) | O(log n)         |
| Binary Search                | O(log n)            | O(1) / O(log n)  |
| Recursion (linear)           | O(n)                | O(n)             |
| Recursion (divide & conquer) | O(n log n)          | O(log n)/O(n)    |

---

Stay consistent. The more you solve, the more naturally time and space analysis will come to you!
